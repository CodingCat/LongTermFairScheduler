Meta VERSION="1" .
Job JOBID="job_201207311004_0001" JOBNAME="random-text-writer" USER="zhunan" SUBMIT_TIME="1343700350987" JOBCONF="hdfs://localhost:9000/Users/zhunan/codes/hadoop/mapred/staging/zhunan/\.staging/job_201207311004_0001/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201207311004_0001" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201207311004_0001" LAUNCH_TIME="1343700351705" TOTAL_MAPS="20" TOTAL_REDUCES="0" JOB_STATUS="PREP" .
Task TASKID="task_201207311004_0001_m_000021" TASK_TYPE="SETUP" START_TIME="1343700352956" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201207311004_0001_m_000021" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000021_0" START_TIME="1343700353825" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201207311004_0001_m_000021" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000021_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700359173" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="setup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Task TASKID="task_201207311004_0001_m_000021" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700362049" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Job JOBID="job_201207311004_0001" JOB_STATUS="RUNNING" .
Task TASKID="task_201207311004_0001_m_000000" TASK_TYPE="MAP" START_TIME="1343700365061" SPLITS="" .
Task TASKID="task_201207311004_0001_m_000001" TASK_TYPE="MAP" START_TIME="1343700365064" SPLITS="" .
Task TASKID="task_201207311004_0001_m_000002" TASK_TYPE="MAP" START_TIME="1343700365065" SPLITS="" .
Task TASKID="task_201207311004_0001_m_000003" TASK_TYPE="MAP" START_TIME="1343700365065" SPLITS="" .
Task TASKID="task_201207311004_0001_m_000004" TASK_TYPE="MAP" START_TIME="1343700374088" SPLITS="" .
Task TASKID="task_201207311004_0001_m_000005" TASK_TYPE="MAP" START_TIME="1343700374090" SPLITS="" .
Task TASKID="task_201207311004_0001_m_000006" TASK_TYPE="MAP" START_TIME="1343700374091" SPLITS="" .
Task TASKID="task_201207311004_0001_m_000007" TASK_TYPE="MAP" START_TIME="1343700374091" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000000" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000000_0" START_TIME="1343700365093" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000000" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700375887" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6542)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6542)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6532)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207311004_0001_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700377118" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6542)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6542)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6532)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000001" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000001_0" START_TIME="1343700365094" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000001" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700375529" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5578)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5578)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5566)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207311004_0001_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700377124" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5578)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5578)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5566)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000002" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000002_0" START_TIME="1343700365153" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000002" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700375866" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5275)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5275)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5267)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207311004_0001_m_000002" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700377131" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5275)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5275)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5267)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000003" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000003_0" START_TIME="1343700365110" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000003" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700375672" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5271)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5271)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5261)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207311004_0001_m_000003" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700377137" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5271)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5271)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5261)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207311004_0001_m_000008" TASK_TYPE="MAP" START_TIME="1343700386193" SPLITS="" .
Task TASKID="task_201207311004_0001_m_000009" TASK_TYPE="MAP" START_TIME="1343700386194" SPLITS="" .
Task TASKID="task_201207311004_0001_m_000010" TASK_TYPE="MAP" START_TIME="1343700386194" SPLITS="" .
Task TASKID="task_201207311004_0001_m_000011" TASK_TYPE="MAP" START_TIME="1343700386195" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000005" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000005_0" START_TIME="1343700375756" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000005" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000005_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700386910" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5274)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5274)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5266)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207311004_0001_m_000005" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700389235" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5274)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5274)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5266)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000006" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000006_0" START_TIME="1343700375928" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000006" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000006_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700387294" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5921)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5921)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5909)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207311004_0001_m_000006" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700389243" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5921)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5921)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5909)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000007" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000007_0" START_TIME="1343700375989" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000007" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000007_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700387067" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5424)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5424)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5412)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207311004_0001_m_000007" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700389262" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5424)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5424)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5412)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000004" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000004_0" START_TIME="1343700375533" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000004" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000004_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700389387" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6227)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6227)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6217)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207311004_0001_m_000004" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700392268" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6227)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6227)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6217)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207311004_0001_m_000012" TASK_TYPE="MAP" START_TIME="1343700395273" SPLITS="" .
Task TASKID="task_201207311004_0001_m_000013" TASK_TYPE="MAP" START_TIME="1343700395273" SPLITS="" .
Task TASKID="task_201207311004_0001_m_000014" TASK_TYPE="MAP" START_TIME="1343700395274" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000008" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000008_0" START_TIME="1343700386916" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000008" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000008_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700396622" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5888)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5888)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5878)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207311004_0001_m_000008" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700398303" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5888)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5888)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5878)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000009" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000009_0" START_TIME="1343700387083" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000009" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000009_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700397123" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5639)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5639)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5629)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207311004_0001_m_000009" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700398304" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5639)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21937)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5639)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5629)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000010" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000010_0" START_TIME="1343700387299" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000010" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000010_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700397367" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5601)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5601)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5591)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207311004_0001_m_000010" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700398305" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5601)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5601)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5591)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207311004_0001_m_000015" TASK_TYPE="MAP" START_TIME="1343700398307" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000011" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000011_0" START_TIME="1343700389418" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000011" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000011_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700401998" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 8 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5393)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5393)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5377)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(8)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(8)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207311004_0001_m_000011" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700404391" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5393)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5393)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5377)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(8)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(8)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207311004_0001_m_000016" TASK_TYPE="MAP" START_TIME="1343700407396" SPLITS="" .
Task TASKID="task_201207311004_0001_m_000017" TASK_TYPE="MAP" START_TIME="1343700407396" SPLITS="" .
Task TASKID="task_201207311004_0001_m_000018" TASK_TYPE="MAP" START_TIME="1343700407397" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000012" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000012_0" START_TIME="1343700396658" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000012" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000012_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700410017" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5191)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5191)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5183)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207311004_0001_m_000012" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700410424" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5191)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5191)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5183)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000014" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000014_0" START_TIME="1343700397380" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000014" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000014_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700410078" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 7 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5226)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5226)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5212)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(7)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(7)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207311004_0001_m_000014" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700410427" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5226)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5226)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5212)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(7)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(7)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207311004_0001_m_000019" TASK_TYPE="MAP" START_TIME="1343700410431" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000013" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000013_0" START_TIME="1343700397149" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000013" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000013_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700410477" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6466)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6466)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6454)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207311004_0001_m_000013" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700413467" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6466)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6466)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6454)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000015" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000015_0" START_TIME="1343700402028" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000015" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000015_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700413402" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6093)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6093)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6081)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207311004_0001_m_000015" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700413470" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6093)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6093)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6081)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000016" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000016_0" START_TIME="1343700410022" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000016" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000016_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700420198" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6014)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6014)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6004)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207311004_0001_m_000016" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700422512" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6014)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6014)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6004)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000017" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000017_0" START_TIME="1343700410083" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000017" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000017_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700420391" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5168)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5168)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5160)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207311004_0001_m_000017" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700422521" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5168)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5168)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5160)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000018" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000018_0" START_TIME="1343700410503" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000018" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000018_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700420472" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5390)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5390)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5380)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207311004_0001_m_000018" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700422523" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5390)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5390)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5380)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000019" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000019_0" START_TIME="1343700413477" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311004_0001_m_000019" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000019_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700425199" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="done with 3 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5224)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5224)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5218)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(3)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(3)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207311004_0001_m_000019" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700425532" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5224)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5224)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5218)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(3)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(3)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207311004_0001_m_000020" TASK_TYPE="CLEANUP" START_TIME="1343700425539" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201207311004_0001_m_000020" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000020_0" START_TIME="1343700425545" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53699" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201207311004_0001_m_000020" TASK_ATTEMPT_ID="attempt_201207311004_0001_m_000020_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343700430800" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="cleanup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Task TASKID="task_201207311004_0001_m_000020" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1343700431549" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21938)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Job JOBID="job_201207311004_0001" FINISH_TIME="1343700431549" JOB_STATUS="SUCCESS" FINISHED_MAPS="20" FINISHED_REDUCES="0" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(112805)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(2310)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(438750)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(112805)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(112597)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(104)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(20)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1700003840)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(2310)][(MAP_OUTPUT_RECORDS)(Map output records)(104)]}" REDUCE_COUNTERS="" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.JobInProgress$Counter)(Job Counters )[(SLOTS_MILLIS_MAPS)(SLOTS_MILLIS_MAPS)(235887)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(20)][(SLOTS_MILLIS_REDUCES)(SLOTS_MILLIS_REDUCES)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(112805)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(2310)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(438750)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(112805)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(112597)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(104)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(20)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1700003840)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(2310)][(MAP_OUTPUT_RECORDS)(Map output records)(104)]}" .
