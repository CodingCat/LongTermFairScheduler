Meta VERSION="1" .
Job JOBID="job_201207311027_0001" JOBNAME="grep-search-small" USER="zhunan" SUBMIT_TIME="1343701786912" JOBCONF="hdfs://localhost:9000/Users/zhunan/codes/hadoop/mapred/staging/zhunan/\.staging/job_201207311027_0001/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201207311027_0001" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201207311027_0001" LAUNCH_TIME="1343701787330" TOTAL_MAPS="3" TOTAL_REDUCES="5" JOB_STATUS="PREP" .
Task TASKID="task_201207311027_0001_m_000004" TASK_TYPE="SETUP" START_TIME="1343701787420" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201207311027_0001_m_000004" TASK_ATTEMPT_ID="attempt_201207311027_0001_m_000004_0" START_TIME="1343701788200" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:54936" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201207311027_0001_m_000004" TASK_ATTEMPT_ID="attempt_201207311027_0001_m_000004_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343701793332" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="setup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21667)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Task TASKID="task_201207311027_0001_m_000004" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1343701793560" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21667)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Job JOBID="job_201207311027_0001" JOB_STATUS="RUNNING" .
Task TASKID="task_201207311027_0001_m_000000" TASK_TYPE="MAP" START_TIME="1343701796577" SPLITS="/default-rack/192\.168\.1\.100" .
Task TASKID="task_201207311027_0001_m_000001" TASK_TYPE="MAP" START_TIME="1343701796579" SPLITS="/default-rack/192\.168\.1\.100" .
Task TASKID="task_201207311027_0001_m_000002" TASK_TYPE="MAP" START_TIME="1343701796580" SPLITS="/default-rack/192\.168\.1\.100" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311027_0001_m_000000" TASK_ATTEMPT_ID="attempt_201207311027_0001_m_000000_0" START_TIME="1343701796590" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:54936" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311027_0001_m_000000" TASK_ATTEMPT_ID="attempt_201207311027_0001_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343701805727" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="hdfs://localhost:9000/workloadgen/data/grep_data/part-00000:0+6542" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(6542)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(6654)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21825)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(5)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(184619008)][(MAP_INPUT_BYTES)(Map input bytes)(6542)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207311027_0001_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343701808637" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(6542)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(6654)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21825)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(5)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(184619008)][(MAP_INPUT_BYTES)(Map input bytes)(6542)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311027_0001_m_000001" TASK_ATTEMPT_ID="attempt_201207311027_0001_m_000001_0" START_TIME="1343701796594" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:54936" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311027_0001_m_000001" TASK_ATTEMPT_ID="attempt_201207311027_0001_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343701805777" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="hdfs://localhost:9000/workloadgen/data/grep_data/part-00001:0+5578" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(5578)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(5690)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21825)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(6)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(184619008)][(MAP_INPUT_BYTES)(Map input bytes)(5578)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207311027_0001_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343701808641" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(5578)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(5690)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21825)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(6)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(184619008)][(MAP_INPUT_BYTES)(Map input bytes)(5578)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311027_0001_m_000002" TASK_ATTEMPT_ID="attempt_201207311027_0001_m_000002_0" START_TIME="1343701796619" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:54936" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207311027_0001_m_000002" TASK_ATTEMPT_ID="attempt_201207311027_0001_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343701806144" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="hdfs://localhost:9000/workloadgen/data/grep_data/part-00002:0+5275" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(5275)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(5387)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21825)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(4)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(184619008)][(MAP_INPUT_BYTES)(Map input bytes)(5275)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207311027_0001_m_000002" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343701808643" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(5275)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(5387)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21825)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(4)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(184619008)][(MAP_INPUT_BYTES)(Map input bytes)(5275)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207311027_0001_r_000000" TASK_TYPE="REDUCE" START_TIME="1343701811655" SPLITS="" .
Task TASKID="task_201207311027_0001_r_000001" TASK_TYPE="REDUCE" START_TIME="1343701811662" SPLITS="" .
Task TASKID="task_201207311027_0001_r_000002" TASK_TYPE="REDUCE" START_TIME="1343701811662" SPLITS="" .
Task TASKID="task_201207311027_0001_r_000003" TASK_TYPE="REDUCE" START_TIME="1343701811663" SPLITS="" .
Task TASKID="task_201207311027_0001_r_000004" TASK_TYPE="REDUCE" START_TIME="1343701826735" SPLITS="" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207311027_0001_r_000000" TASK_ATTEMPT_ID="attempt_201207311027_0001_r_000000_0" START_TIME="1343701811700" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:54936" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207311027_0001_r_000000" TASK_ATTEMPT_ID="attempt_201207311027_0001_r_000000_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1343701825267" SORT_FINISHED="1343701825308" FINISH_TIME="1343701829830" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="reduce > reduce" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21674)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(18)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207311027_0001_r_000000" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1343701832816" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21674)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(18)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207311027_0001_r_000002" TASK_ATTEMPT_ID="attempt_201207311027_0001_r_000002_0" START_TIME="1343701811743" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:54936" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207311027_0001_r_000002" TASK_ATTEMPT_ID="attempt_201207311027_0001_r_000002_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1343701831347" SORT_FINISHED="1343701831371" FINISH_TIME="1343701834003" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="reduce > reduce" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21674)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(18)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207311027_0001_r_000002" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1343701835825" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21674)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(18)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207311027_0001_r_000003" TASK_ATTEMPT_ID="attempt_201207311027_0001_r_000003_0" START_TIME="1343701811703" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:54936" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207311027_0001_r_000003" TASK_ATTEMPT_ID="attempt_201207311027_0001_r_000003_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1343701830063" SORT_FINISHED="1343701830377" FINISH_TIME="1343701833634" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="reduce > reduce" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21674)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(18)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207311027_0001_r_000003" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1343701835828" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21674)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(18)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207311027_0001_r_000001" TASK_ATTEMPT_ID="attempt_201207311027_0001_r_000001_0" START_TIME="1343701811706" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:54936" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207311027_0001_r_000001" TASK_ATTEMPT_ID="attempt_201207311027_0001_r_000001_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1343701829625" SORT_FINISHED="1343701829849" FINISH_TIME="1343701836282" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="reduce > reduce" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21674)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(18)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207311027_0001_r_000001" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1343701839125" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21674)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(18)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207311027_0001_r_000004" TASK_ATTEMPT_ID="attempt_201207311027_0001_r_000004_0" START_TIME="1343701829852" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:54936" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207311027_0001_r_000004" TASK_ATTEMPT_ID="attempt_201207311027_0001_r_000004_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1343701845497" SORT_FINISHED="1343701845540" FINISH_TIME="1343701850508" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="reduce > reduce" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21674)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(18)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207311027_0001_r_000004" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1343701851195" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21674)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(18)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207311027_0001_m_000003" TASK_TYPE="CLEANUP" START_TIME="1343701851199" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201207311027_0001_m_000003" TASK_ATTEMPT_ID="attempt_201207311027_0001_m_000003_0" START_TIME="1343701851280" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:54936" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201207311027_0001_m_000003" TASK_ATTEMPT_ID="attempt_201207311027_0001_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343701862638" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="cleanup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21667)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Task TASKID="task_201207311027_0001_m_000003" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1343701863277" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21667)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Job JOBID="job_201207311027_0001" FINISH_TIME="1343701863278" JOB_STATUS="SUCCESS" FINISHED_MAPS="3" FINISHED_REDUCES="5" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(17395)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(17731)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(65475)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(90)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(15)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(553857024)][(MAP_INPUT_BYTES)(Map input bytes)(17395)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(336)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)]}" REDUCE_COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(430)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(30)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(108370)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(430)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(90)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(425000960)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(17395)]}{(org\.apache\.hadoop\.mapred\.JobInProgress$Counter)(Job Counters )[(SLOTS_MILLIS_MAPS)(SLOTS_MILLIS_MAPS)(44335)][(TOTAL_LAUNCHED_REDUCES)(Launched reduce tasks)(5)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(3)][(DATA_LOCAL_MAPS)(Data-local map tasks)(3)][(SLOTS_MILLIS_REDUCES)(SLOTS_MILLIS_REDUCES)(107553)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(430)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(30)][(HDFS_BYTES_READ)(HDFS_BYTES_READ)(17731)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(173845)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(430)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(90)][(MAP_INPUT_RECORDS)(Map input records)(15)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(90)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(978857984)][(MAP_INPUT_BYTES)(Map input bytes)(17395)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(336)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)]}" .
