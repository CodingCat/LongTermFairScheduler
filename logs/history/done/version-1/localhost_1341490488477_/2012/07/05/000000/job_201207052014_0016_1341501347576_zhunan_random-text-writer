Meta VERSION="1" .
Job JOBID="job_201207052014_0016" JOBNAME="random-text-writer" USER="zhunan" SUBMIT_TIME="1341501347576" JOBCONF="hdfs://localhost:9000/Users/zhunan/codes/hadoop/mapred/staging/zhunan/\.staging/job_201207052014_0016/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201207052014_0016" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201207052014_0016" LAUNCH_TIME="1341501347891" TOTAL_MAPS="20" TOTAL_REDUCES="0" JOB_STATUS="PREP" .
Task TASKID="task_201207052014_0016_m_000021" TASK_TYPE="SETUP" START_TIME="1341501349467" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201207052014_0016_m_000021" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000021_0" START_TIME="1341501350050" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201207052014_0016_m_000021" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000021_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501358296" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="setup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Task TASKID="task_201207052014_0016_m_000021" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501358529" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Job JOBID="job_201207052014_0016" JOB_STATUS="RUNNING" .
Task TASKID="task_201207052014_0016_m_000000" TASK_TYPE="MAP" START_TIME="1341501358530" SPLITS="" .
Task TASKID="task_201207052014_0016_m_000001" TASK_TYPE="MAP" START_TIME="1341501361532" SPLITS="" .
Task TASKID="task_201207052014_0016_m_000002" TASK_TYPE="MAP" START_TIME="1341501364541" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000000" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000000_0" START_TIME="1341501358533" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000000" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501365927" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5451)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5451)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5443)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501367560" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5451)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5451)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5443)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000003" TASK_TYPE="MAP" START_TIME="1341501370565" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000001" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000001_0" START_TIME="1341501361564" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000001" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501371304" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5178)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5178)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5170)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501373572" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5178)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5178)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5170)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000004" TASK_TYPE="MAP" START_TIME="1341501376576" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000002" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000002_0" START_TIME="1341501365956" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000002" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501379458" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5638)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5638)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5626)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000002" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501379588" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5638)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5638)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5626)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000005" TASK_TYPE="MAP" START_TIME="1341501379589" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000003" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000003_0" START_TIME="1341501371320" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000003" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501381558" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 3 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5387)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5387)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5381)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(3)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(3)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000003" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501382605" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5387)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5387)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5381)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(3)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(3)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000006" TASK_TYPE="MAP" START_TIME="1341501388680" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000004" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000004_0" START_TIME="1341501379491" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000004" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000004_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501390150" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5888)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5888)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5878)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000004" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501391723" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5888)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5888)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5878)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000007" TASK_TYPE="MAP" START_TIME="1341501391725" SPLITS="" .
Task TASKID="task_201207052014_0016_m_000008" TASK_TYPE="MAP" START_TIME="1341501394728" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000005" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000005_0" START_TIME="1341501381583" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000005" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000005_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501394899" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6031)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6031)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6023)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000005" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501397736" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6031)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6031)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6023)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000006" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000006_0" START_TIME="1341501390161" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000006" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000006_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501397098" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 7 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5963)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5963)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5949)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(7)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(7)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000006" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501397737" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5963)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5963)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5949)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(7)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(7)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000009" TASK_TYPE="MAP" START_TIME="1341501400740" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000007" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000007_0" START_TIME="1341501394917" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000007" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000007_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501402753" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6270)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6270)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6260)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000007" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501403763" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6270)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6270)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6260)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000010" TASK_TYPE="MAP" START_TIME="1341501406767" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000008" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000008_0" START_TIME="1341501397127" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000008" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000008_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501409654" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6515)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6515)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6503)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000008" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501409806" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6515)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6515)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6503)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000011" TASK_TYPE="MAP" START_TIME="1341501409808" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000009" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000009_0" START_TIME="1341501402767" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000009" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000009_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501411280" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5697)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5697)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5687)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000009" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501412816" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5697)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5697)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5687)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0016_m_000012" TASK_TYPE="MAP" START_TIME="1341501418854" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000010" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000010_0" START_TIME="1341501409657" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000010" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000010_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501420418" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5596)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5596)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5586)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000010" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501421861" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5596)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5596)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5586)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000013" TASK_TYPE="MAP" START_TIME="1341501421862" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000011" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000011_0" START_TIME="1341501411296" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000011" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000011_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501424882" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5211)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5211)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5203)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000011" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501427873" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5211)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5211)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5203)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000014" TASK_TYPE="MAP" START_TIME="1341501427876" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000012" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000012_0" START_TIME="1341501420423" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000012" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000012_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501429386" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 9 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5765)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5765)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5747)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(9)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(9)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000012" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501430911" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5765)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5765)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5747)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(9)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(9)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000015" TASK_TYPE="MAP" START_TIME="1341501433914" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000013" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000013_0" START_TIME="1341501424886" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000013" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000013_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501436843" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 8 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5552)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5552)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5536)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(8)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(8)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000013" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501436930" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5552)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5552)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5536)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(8)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(8)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000016" TASK_TYPE="MAP" START_TIME="1341501436935" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000014" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000014_0" START_TIME="1341501429434" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000014" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000014_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501437980" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5148)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5148)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5140)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000014" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501439967" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5148)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5148)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5140)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000017" TASK_TYPE="MAP" START_TIME="1341501445981" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000015" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000015_0" START_TIME="1341501436847" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000015" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000015_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501447406" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5735)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5735)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5723)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000015" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501448986" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5735)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5735)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5723)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000016" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000016_0" START_TIME="1341501438017" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000016" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000016_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501448484" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5841)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5841)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5833)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000016" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501448987" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5841)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5841)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5833)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000018" TASK_TYPE="MAP" START_TIME="1341501448987" SPLITS="" .
Task TASKID="task_201207052014_0016_m_000019" TASK_TYPE="MAP" START_TIME="1341501455000" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000017" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000017_0" START_TIME="1341501447409" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000017" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000017_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501456352" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5479)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5479)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5467)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000017" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501458005" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5479)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5479)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5467)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000018" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000018_0" START_TIME="1341501449009" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000018" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000018_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501457583" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5494)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5494)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5484)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000018" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501458006" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5494)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5494)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5484)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000019" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000019_0" START_TIME="1341501456378" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0016_m_000019" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000019_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501466923" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 3 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5457)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5457)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5451)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(3)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(3)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000019" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501467015" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5457)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5457)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5451)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(3)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(3)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0016_m_000020" TASK_TYPE="CLEANUP" START_TIME="1341501467017" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201207052014_0016_m_000020" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000020_0" START_TIME="1341501467031" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201207052014_0016_m_000020" TASK_ATTEMPT_ID="attempt_201207052014_0016_m_000020_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341501473750" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="cleanup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Task TASKID="task_201207052014_0016_m_000020" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1341501476025" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Job JOBID="job_201207052014_0016" FINISH_TIME="1341501476026" JOB_STATUS="SUCCESS" FINISHED_MAPS="20" FINISHED_REDUCES="0" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(113296)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(2310)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(437210)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(113296)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(113090)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(103)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(20)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1700003840)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(2310)][(MAP_OUTPUT_RECORDS)(Map output records)(103)]}" REDUCE_COUNTERS="" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.JobInProgress$Counter)(Job Counters )[(SLOTS_MILLIS_MAPS)(SLOTS_MILLIS_MAPS)(218528)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(20)][(SLOTS_MILLIS_REDUCES)(SLOTS_MILLIS_REDUCES)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(113296)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(2310)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(437210)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(113296)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(113090)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(103)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(20)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1700003840)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(2310)][(MAP_OUTPUT_RECORDS)(Map output records)(103)]}" .
