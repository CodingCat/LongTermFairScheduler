Meta VERSION="1" .
Job JOBID="job_201207052014_0009" JOBNAME="random-text-writer" USER="zhunan" SUBMIT_TIME="1341498552723" JOBCONF="hdfs://localhost:9000/Users/zhunan/codes/hadoop/mapred/staging/zhunan/\.staging/job_201207052014_0009/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201207052014_0009" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201207052014_0009" LAUNCH_TIME="1341498552965" TOTAL_MAPS="20" TOTAL_REDUCES="0" JOB_STATUS="PREP" .
Task TASKID="task_201207052014_0009_m_000021" TASK_TYPE="SETUP" START_TIME="1341498553937" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201207052014_0009_m_000021" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000021_0" START_TIME="1341498554472" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201207052014_0009_m_000021" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000021_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498560793" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="setup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Task TASKID="task_201207052014_0009_m_000021" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498562956" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Job JOBID="job_201207052014_0009" JOB_STATUS="RUNNING" .
Task TASKID="task_201207052014_0009_m_000000" TASK_TYPE="MAP" START_TIME="1341498562958" SPLITS="" .
Task TASKID="task_201207052014_0009_m_000001" TASK_TYPE="MAP" START_TIME="1341498565962" SPLITS="" .
Task TASKID="task_201207052014_0009_m_000002" TASK_TYPE="MAP" START_TIME="1341498568967" SPLITS="" .
Task TASKID="task_201207052014_0009_m_000003" TASK_TYPE="MAP" START_TIME="1341498571969" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000000" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000000_0" START_TIME="1341498562988" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000000" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498572629" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5399)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5399)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5387)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498574973" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5399)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5399)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5387)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000001" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000001_0" START_TIME="1341498565988" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000001" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498575569" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5282)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5282)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5274)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498577977" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5282)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5282)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5274)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000004" TASK_TYPE="MAP" START_TIME="1341498577979" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000002" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000002_0" START_TIME="1341498572667" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000002" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498579498" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6354)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6354)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6344)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000002" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498580984" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6354)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6354)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6344)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000005" TASK_TYPE="MAP" START_TIME="1341498580986" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000003" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000003_0" START_TIME="1341498575574" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000003" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498582381" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5770)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5770)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5758)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000003" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498583997" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5770)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5770)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5758)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000006" TASK_TYPE="MAP" START_TIME="1341498587000" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000005" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000005_0" START_TIME="1341498582400" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000005" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000005_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498589684" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6078)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6078)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6068)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000005" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498590007" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6078)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6078)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6068)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000007" TASK_TYPE="MAP" START_TIME="1341498590008" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000004" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000004_0" START_TIME="1341498579501" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000004" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000004_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498590049" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5455)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5455)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5447)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000004" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498593016" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5455)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5455)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5447)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000008" TASK_TYPE="MAP" START_TIME="1341498596022" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000006" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000006_0" START_TIME="1341498589689" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000006" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000006_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498598509" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5167)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5167)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5159)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000006" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498599028" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5167)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5167)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5159)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000007" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000007_0" START_TIME="1341498590092" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000007" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000007_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498598792" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5719)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5719)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5707)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000007" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498599030" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5719)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5719)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5707)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000009" TASK_TYPE="MAP" START_TIME="1341498599031" SPLITS="" .
Task TASKID="task_201207052014_0009_m_000010" TASK_TYPE="MAP" START_TIME="1341498605049" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000008" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000008_0" START_TIME="1341498598523" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000008" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000008_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498607154" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6285)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6285)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6277)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000008" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498608079" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6285)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6285)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6277)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000009" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000009_0" START_TIME="1341498599054" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000009" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000009_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498607409" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6123)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6123)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6113)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000009" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498608080" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6123)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(115)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21860)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6123)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6113)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(115)]}" .
Task TASKID="task_201207052014_0009_m_000011" TASK_TYPE="MAP" START_TIME="1341498608081" SPLITS="" .
Task TASKID="task_201207052014_0009_m_000012" TASK_TYPE="MAP" START_TIME="1341498614088" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000010" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000010_0" START_TIME="1341498607169" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000010" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000010_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498615512" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5537)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5537)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5529)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000010" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498617096" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5537)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5537)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5529)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000011" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000011_0" START_TIME="1341498608094" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000011" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000011_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498616157" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5615)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5615)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5607)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000011" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498617097" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5615)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5615)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5607)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000013" TASK_TYPE="MAP" START_TIME="1341498617108" SPLITS="" .
Task TASKID="task_201207052014_0009_m_000014" TASK_TYPE="MAP" START_TIME="1341498623119" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000013" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000013_0" START_TIME="1341498617125" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000013" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000013_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498624726" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5866)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5866)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5858)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000013" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498626128" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5866)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5866)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5858)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000015" TASK_TYPE="MAP" START_TIME="1341498626131" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000012" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000012_0" START_TIME="1341498615535" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000012" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000012_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498626300" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5294)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5294)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5282)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000012" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498629152" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5294)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5294)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5282)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000016" TASK_TYPE="MAP" START_TIME="1341498632155" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000014" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000014_0" START_TIME="1341498624736" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000014" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000014_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498635157" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5392)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5392)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5380)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000014" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498635170" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5392)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5392)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5380)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000015" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000015_0" START_TIME="1341498626334" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000015" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000015_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498633980" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6777)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6777)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6767)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000015" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498635174" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6777)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6777)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6767)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000017" TASK_TYPE="MAP" START_TIME="1341498635175" SPLITS="" .
Task TASKID="task_201207052014_0009_m_000018" TASK_TYPE="MAP" START_TIME="1341498641188" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000016" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000016_0" START_TIME="1341498633983" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000016" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000016_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498641903" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6029)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6029)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6019)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000016" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498644207" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6029)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6029)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6019)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000017" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000017_0" START_TIME="1341498635201" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000017" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000017_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498643063" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5673)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5673)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5663)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000017" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498644208" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5673)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5673)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5663)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000019" TASK_TYPE="MAP" START_TIME="1341498644209" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000018" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000018_0" START_TIME="1341498641907" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000018" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000018_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498649479" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5871)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5871)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5863)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000018" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498650218" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5871)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5871)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5863)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000019" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000019_0" START_TIME="1341498644237" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0009_m_000019" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000019_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498651552" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6403)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6403)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6393)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000019" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498653223" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6403)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(116)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6403)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6393)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(116)]}" .
Task TASKID="task_201207052014_0009_m_000020" TASK_TYPE="CLEANUP" START_TIME="1341498653226" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201207052014_0009_m_000020" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000020_0" START_TIME="1341498653231" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201207052014_0009_m_000020" TASK_ATTEMPT_ID="attempt_201207052014_0009_m_000020_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341498659385" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="cleanup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Task TASKID="task_201207052014_0009_m_000020" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1341498662233" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21861)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Job JOBID="job_201207052014_0009" FINISH_TIME="1341498662234" JOB_STATUS="SUCCESS" FINISHED_MAPS="20" FINISHED_REDUCES="0" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(116089)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(2310)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(437210)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(116089)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(115895)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(97)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(20)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1700003840)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(2310)][(MAP_OUTPUT_RECORDS)(Map output records)(97)]}" REDUCE_COUNTERS="" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.JobInProgress$Counter)(Job Counters )[(SLOTS_MILLIS_MAPS)(SLOTS_MILLIS_MAPS)(181181)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(20)][(SLOTS_MILLIS_REDUCES)(SLOTS_MILLIS_REDUCES)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(116089)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(2310)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(437210)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(116089)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(115895)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(97)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(20)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1700003840)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(2310)][(MAP_OUTPUT_RECORDS)(Map output records)(97)]}" .
