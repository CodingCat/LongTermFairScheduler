Meta VERSION="1" .
Job JOBID="job_201207052014_0006" JOBNAME="random-text-writer" USER="zhunan" SUBMIT_TIME="1341494964290" JOBCONF="hdfs://localhost:9000/Users/zhunan/codes/hadoop/mapred/staging/zhunan/\.staging/job_201207052014_0006/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201207052014_0006" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201207052014_0006" LAUNCH_TIME="1341494964487" TOTAL_MAPS="20" TOTAL_REDUCES="0" JOB_STATUS="PREP" .
Task TASKID="task_201207052014_0006_m_000021" TASK_TYPE="SETUP" START_TIME="1341494966651" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201207052014_0006_m_000021" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000021_0" START_TIME="1341494967133" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201207052014_0006_m_000021" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000021_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494973382" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="setup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Task TASKID="task_201207052014_0006_m_000021" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494975671" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Job JOBID="job_201207052014_0006" JOB_STATUS="RUNNING" .
Task TASKID="task_201207052014_0006_m_000000" TASK_TYPE="MAP" START_TIME="1341494975672" SPLITS="" .
Task TASKID="task_201207052014_0006_m_000001" TASK_TYPE="MAP" START_TIME="1341494978685" SPLITS="" .
Task TASKID="task_201207052014_0006_m_000002" TASK_TYPE="MAP" START_TIME="1341494981689" SPLITS="" .
Task TASKID="task_201207052014_0006_m_000003" TASK_TYPE="MAP" START_TIME="1341494984691" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000000" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000000_0" START_TIME="1341494975678" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000000" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494984774" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6373)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6373)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6361)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494987695" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6373)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6373)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6361)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000001" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000001_0" START_TIME="1341494978715" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000001" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494987974" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 7 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5870)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5870)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5856)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(7)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(7)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494990701" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5870)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5870)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5856)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(7)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(7)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000004" TASK_TYPE="MAP" START_TIME="1341494990702" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000002" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000002_0" START_TIME="1341494984801" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000002" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494992394" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6574)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6574)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6566)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000002" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494993714" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6574)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6574)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6566)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000005" TASK_TYPE="MAP" START_TIME="1341494996740" SPLITS="" .
Task TASKID="task_201207052014_0006_m_000006" TASK_TYPE="MAP" START_TIME="1341494999744" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000003" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000003_0" START_TIME="1341494988020" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000003" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495000147" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5392)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5392)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5380)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000003" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495002747" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5392)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5392)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5380)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000004" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000004_0" START_TIME="1341494992417" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000004" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000004_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495000720" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6774)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6774)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6764)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000004" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495002749" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6774)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6774)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6764)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000007" TASK_TYPE="MAP" START_TIME="1341495008755" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000005" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000005_0" START_TIME="1341495000179" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000005" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000005_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495009929" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5331)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5331)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5321)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000005" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495011762" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5331)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5331)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5321)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000006" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000006_0" START_TIME="1341495000742" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000006" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000006_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495010350" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 8 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5513)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5513)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5497)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(8)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(8)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000006" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495011764" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5513)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5513)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5497)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(8)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(8)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000008" TASK_TYPE="MAP" START_TIME="1341495011766" SPLITS="" .
Task TASKID="task_201207052014_0006_m_000009" TASK_TYPE="MAP" START_TIME="1341495014777" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000007" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000007_0" START_TIME="1341495009934" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000007" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000007_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495017023" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(7210)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(7210)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(7200)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000007" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495017782" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(7210)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(7210)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(7200)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000010" TASK_TYPE="MAP" START_TIME="1341495017784" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000008" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000008_0" START_TIME="1341495011792" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000008" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000008_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495019119" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6911)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6911)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6901)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000008" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495020787" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6911)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6911)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6901)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000011" TASK_TYPE="MAP" START_TIME="1341495023793" SPLITS="" .
Task TASKID="task_201207052014_0006_m_000012" TASK_TYPE="MAP" START_TIME="1341495026798" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000009" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000009_0" START_TIME="1341495017060" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000009" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000009_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495027443" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6625)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6625)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6613)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
Task TASKID="task_201207052014_0006_m_000009" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495029821" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6625)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(111)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21856)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6625)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6613)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(111)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000010" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000010_0" START_TIME="1341495019161" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000010" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000010_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495029653" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5915)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5915)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5903)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000010" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495029822" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5915)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5915)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5903)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000013" TASK_TYPE="MAP" START_TIME="1341495032826" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000011" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000011_0" START_TIME="1341495027495" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000011" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000011_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495034612" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5955)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5955)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5945)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000011" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495035833" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5955)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5955)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5945)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000014" TASK_TYPE="MAP" START_TIME="1341495035834" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000012" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000012_0" START_TIME="1341495029677" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000012" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000012_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495037167" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5853)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5853)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5843)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000012" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495038847" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5853)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5853)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5843)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000015" TASK_TYPE="MAP" START_TIME="1341495041851" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000013" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000013_0" START_TIME="1341495034632" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000013" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000013_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495044816" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5327)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5327)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5315)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000013" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495044859" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5327)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5327)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5315)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000014" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000014_0" START_TIME="1341495037205" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000014" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000014_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495044340" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6919)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6919)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6911)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000014" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495044862" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6919)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6919)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6911)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000016" TASK_TYPE="MAP" START_TIME="1341495044863" SPLITS="" .
Task TASKID="task_201207052014_0006_m_000017" TASK_TYPE="MAP" START_TIME="1341495050869" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000015" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000015_0" START_TIME="1341495044357" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000015" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000015_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495052781" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6618)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6618)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6610)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000015" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495053875" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6618)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6618)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6610)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000016" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000016_0" START_TIME="1341495044868" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000016" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000016_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495053169" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(7094)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(7094)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(7082)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000016" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495053876" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(7094)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(7094)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(7082)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000018" TASK_TYPE="MAP" START_TIME="1341495053877" SPLITS="" .
Task TASKID="task_201207052014_0006_m_000019" TASK_TYPE="MAP" START_TIME="1341495059884" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000017" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000017_0" START_TIME="1341495052792" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000017" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000017_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495061228" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6519)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6519)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6511)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000017" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495062888" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6519)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6519)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6511)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000018" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000018_0" START_TIME="1341495053882" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000018" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000018_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495061898" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6994)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6994)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6982)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000018" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495062891" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6994)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6994)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6982)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000019" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000019_0" START_TIME="1341495061230" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0006_m_000019" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000019_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495067772" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5246)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5246)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5238)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000019" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495068905" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5246)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(112)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5246)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5238)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(112)]}" .
Task TASKID="task_201207052014_0006_m_000020" TASK_TYPE="CLEANUP" START_TIME="1341495068925" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201207052014_0006_m_000020" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000020_0" START_TIME="1341495068935" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201207052014_0006_m_000020" TASK_ATTEMPT_ID="attempt_201207052014_0006_m_000020_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341495075272" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="cleanup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Task TASKID="task_201207052014_0006_m_000020" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1341495077931" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21857)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Job JOBID="job_201207052014_0006" FINISH_TIME="1341495077932" JOB_STATUS="SUCCESS" FINISHED_MAPS="20" FINISHED_REDUCES="0" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(125013)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(2230)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(437130)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(125013)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(124799)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(107)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(20)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1700003840)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(2230)][(MAP_OUTPUT_RECORDS)(Map output records)(107)]}" REDUCE_COUNTERS="" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.JobInProgress$Counter)(Job Counters )[(SLOTS_MILLIS_MAPS)(SLOTS_MILLIS_MAPS)(185258)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(20)][(SLOTS_MILLIS_REDUCES)(SLOTS_MILLIS_REDUCES)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(125013)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(2230)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(437130)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(125013)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(124799)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(107)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(20)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1700003840)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(2230)][(MAP_OUTPUT_RECORDS)(Map output records)(107)]}" .
