Meta VERSION="1" .
Job JOBID="job_201207052014_0013" JOBNAME="random-text-writer" USER="zhunan" SUBMIT_TIME="1341500728159" JOBCONF="hdfs://localhost:9000/Users/zhunan/codes/hadoop/mapred/staging/zhunan/\.staging/job_201207052014_0013/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201207052014_0013" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201207052014_0013" LAUNCH_TIME="1341500728432" TOTAL_MAPS="20" TOTAL_REDUCES="0" JOB_STATUS="PREP" .
Task TASKID="task_201207052014_0013_m_000021" TASK_TYPE="SETUP" START_TIME="1341500730622" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201207052014_0013_m_000021" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000021_0" START_TIME="1341500731105" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201207052014_0013_m_000021" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000021_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500737634" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="setup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Task TASKID="task_201207052014_0013_m_000021" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500739650" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Job JOBID="job_201207052014_0013" JOB_STATUS="RUNNING" .
Task TASKID="task_201207052014_0013_m_000000" TASK_TYPE="MAP" START_TIME="1341500739652" SPLITS="" .
Task TASKID="task_201207052014_0013_m_000001" TASK_TYPE="MAP" START_TIME="1341500742654" SPLITS="" .
Task TASKID="task_201207052014_0013_m_000002" TASK_TYPE="MAP" START_TIME="1341500745658" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000000" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000000_0" START_TIME="1341500739658" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000000" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500746365" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6105)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6105)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6093)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500748661" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6105)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6105)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6093)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000003" TASK_TYPE="MAP" START_TIME="1341500748662" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000001" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000001_0" START_TIME="1341500742673" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000001" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500750383" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5616)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5616)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5606)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500751683" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5616)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5616)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5606)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000004" TASK_TYPE="MAP" START_TIME="1341500751684" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000002" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000002_0" START_TIME="1341500746400" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000002" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500753676" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5311)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5311)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5301)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000002" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500754688" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5311)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5311)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5301)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000005" TASK_TYPE="MAP" START_TIME="1341500757692" SPLITS="" .
Task TASKID="task_201207052014_0013_m_000006" TASK_TYPE="MAP" START_TIME="1341500760727" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000003" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000003_0" START_TIME="1341500750413" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000003" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500761046" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5354)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5354)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5342)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000003" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500763751" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5354)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5354)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5342)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000004" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000004_0" START_TIME="1341500753705" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000004" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000004_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500763726" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6361)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6361)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6349)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000004" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500763753" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6361)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6361)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6349)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000007" TASK_TYPE="MAP" START_TIME="1341500766805" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000005" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000005_0" START_TIME="1341500761049" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000005" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000005_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500769253" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6537)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6537)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6527)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000005" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500769817" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6537)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6537)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6527)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000008" TASK_TYPE="MAP" START_TIME="1341500769818" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000006" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000006_0" START_TIME="1341500763754" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000006" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000006_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500771361" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(7020)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(7020)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(7010)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000006" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500772828" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(7020)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(7020)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(7010)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000009" TASK_TYPE="MAP" START_TIME="1341500775831" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000007" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000007_0" START_TIME="1341500769258" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000007" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000007_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500776645" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5968)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5968)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5960)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000007" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500778836" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5968)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5968)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5960)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000010" TASK_TYPE="MAP" START_TIME="1341500778837" SPLITS="" .
Task TASKID="task_201207052014_0013_m_000011" TASK_TYPE="MAP" START_TIME="1341500781842" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000008" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000008_0" START_TIME="1341500771398" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000008" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000008_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500781948" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5811)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5811)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5799)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000008" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500784882" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5811)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5811)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5799)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000009" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000009_0" START_TIME="1341500776668" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000009" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000009_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500783440" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(7129)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(7129)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(7121)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000009" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500784883" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(7129)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(127)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21872)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(7129)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(7121)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(127)]}" .
Task TASKID="task_201207052014_0013_m_000012" TASK_TYPE="MAP" START_TIME="1341500787895" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000010" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000010_0" START_TIME="1341500781980" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000010" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000010_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500789812" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5543)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5543)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5535)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000010" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500790899" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5543)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5543)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5535)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000013" TASK_TYPE="MAP" START_TIME="1341500790901" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000011" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000011_0" START_TIME="1341500783483" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000011" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000011_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500794414" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 7 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5206)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5206)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5192)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(7)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(7)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000011" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500796906" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5206)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5206)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5192)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(7)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(7)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000014" TASK_TYPE="MAP" START_TIME="1341500796907" SPLITS="" .
Task TASKID="task_201207052014_0013_m_000015" TASK_TYPE="MAP" START_TIME="1341500799910" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000012" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000012_0" START_TIME="1341500789841" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000012" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000012_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500799999" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5155)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5155)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5143)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000012" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500802913" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5155)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5155)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5143)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000013" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000013_0" START_TIME="1341500794436" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000013" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000013_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500801396" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5417)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5417)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5405)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000013" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500802914" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5417)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5417)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5405)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000016" TASK_TYPE="MAP" START_TIME="1341500805957" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000014" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000014_0" START_TIME="1341500800015" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000014" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000014_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500807379" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6203)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6203)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6191)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000014" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500808960" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6203)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6203)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6191)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000017" TASK_TYPE="MAP" START_TIME="1341500808961" SPLITS="" .
Task TASKID="task_201207052014_0013_m_000018" TASK_TYPE="MAP" START_TIME="1341500811963" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000015" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000015_0" START_TIME="1341500801400" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000015" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000015_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500812408" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6398)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6398)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6388)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000015" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500814966" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6398)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6398)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6388)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000016" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000016_0" START_TIME="1341500807400" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000016" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000016_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500814099" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5329)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5329)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5319)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000016" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500814967" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5329)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5329)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5319)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000019" TASK_TYPE="MAP" START_TIME="1341500817971" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000017" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000017_0" START_TIME="1341500812410" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000017" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000017_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500819607" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5380)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5380)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5372)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000017" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500820984" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5380)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5380)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5372)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000018" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000018_0" START_TIME="1341500814142" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000018" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000018_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500821775" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 7 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5886)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5886)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5872)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(7)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(7)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000018" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500823988" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5886)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5886)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5872)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(7)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(7)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000019" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000019_0" START_TIME="1341500819620" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0013_m_000019" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000019_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500826414" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5393)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5393)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5383)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000019" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500826992" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5393)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(128)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5393)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5383)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(128)]}" .
Task TASKID="task_201207052014_0013_m_000020" TASK_TYPE="CLEANUP" START_TIME="1341500826998" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201207052014_0013_m_000020" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000020_0" START_TIME="1341500827002" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201207052014_0013_m_000020" TASK_ATTEMPT_ID="attempt_201207052014_0013_m_000020_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341500833163" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="cleanup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Task TASKID="task_201207052014_0013_m_000020" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1341500836006" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21873)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Job JOBID="job_201207052014_0013" FINISH_TIME="1341500836008" JOB_STATUS="SUCCESS" FINISHED_MAPS="20" FINISHED_REDUCES="0" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(117122)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(2550)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(437450)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(117122)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(116908)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(107)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(20)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1700003840)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(2550)][(MAP_OUTPUT_RECORDS)(Map output records)(107)]}" REDUCE_COUNTERS="" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.JobInProgress$Counter)(Job Counters )[(SLOTS_MILLIS_MAPS)(SLOTS_MILLIS_MAPS)(178133)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(20)][(SLOTS_MILLIS_REDUCES)(SLOTS_MILLIS_REDUCES)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(117122)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(2550)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(437450)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(117122)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(116908)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(107)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(20)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1700003840)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(2550)][(MAP_OUTPUT_RECORDS)(Map output records)(107)]}" .
