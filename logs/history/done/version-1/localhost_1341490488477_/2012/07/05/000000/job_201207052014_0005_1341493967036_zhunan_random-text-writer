Meta VERSION="1" .
Job JOBID="job_201207052014_0005" JOBNAME="random-text-writer" USER="zhunan" SUBMIT_TIME="1341493967036" JOBCONF="hdfs://localhost:9000/Users/zhunan/codes/hadoop/mapred/staging/zhunan/\.staging/job_201207052014_0005/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201207052014_0005" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201207052014_0005" LAUNCH_TIME="1341493967810" TOTAL_MAPS="20" TOTAL_REDUCES="0" JOB_STATUS="PREP" .
Task TASKID="task_201207052014_0005_r_000001" TASK_TYPE="SETUP" START_TIME="1341493974948" SPLITS="" .
ReduceAttempt TASK_TYPE="SETUP" TASKID="task_201207052014_0005_r_000001" TASK_ATTEMPT_ID="attempt_201207052014_0005_r_000001_0" START_TIME="1341493975739" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="SETUP" TASKID="task_201207052014_0005_r_000001" TASK_ATTEMPT_ID="attempt_201207052014_0005_r_000001_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1341493983144" SORT_FINISHED="1341493983144" FINISH_TIME="1341493983145" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="setup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(0)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207052014_0005_r_000001" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1341493983973" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(0)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Job JOBID="job_201207052014_0005" JOB_STATUS="RUNNING" .
Task TASKID="task_201207052014_0005_m_000000" TASK_TYPE="MAP" START_TIME="1341493983974" SPLITS="" .
Task TASKID="task_201207052014_0005_m_000001" TASK_TYPE="MAP" START_TIME="1341493986989" SPLITS="" .
Task TASKID="task_201207052014_0005_m_000002" TASK_TYPE="MAP" START_TIME="1341493993012" SPLITS="" .
Task TASKID="task_201207052014_0005_m_000003" TASK_TYPE="MAP" START_TIME="1341493996023" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000000" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000000_0" START_TIME="1341493985798" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000000" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341493996058" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6359)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6359)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6349)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341493999029" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6359)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6359)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6349)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000001" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000001_0" START_TIME="1341493988429" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000001" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341493999391" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5896)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5896)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5888)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494002036" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5896)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5896)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5888)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000004" TASK_TYPE="MAP" START_TIME="1341494002037" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000002" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000002_0" START_TIME="1341493996082" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000002" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494003073" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6267)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6267)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6255)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000002" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494005042" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6267)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6267)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6255)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000005" TASK_TYPE="MAP" START_TIME="1341494005044" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000003" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000003_0" START_TIME="1341493999421" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000003" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494006407" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5418)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5418)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5406)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000003" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494008051" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5418)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5418)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5406)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000006" TASK_TYPE="MAP" START_TIME="1341494011091" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000004" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000004_0" START_TIME="1341494003103" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000004" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000004_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494014054" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5560)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5560)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5550)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000004" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494014109" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5560)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5560)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5550)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000007" TASK_TYPE="MAP" START_TIME="1341494014112" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000005" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000005_0" START_TIME="1341494006438" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000005" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000005_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494017295" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6218)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6218)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6206)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000005" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494020127" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6218)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6218)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6206)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000008" TASK_TYPE="MAP" START_TIME="1341494020128" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000006" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000006_0" START_TIME="1341494014059" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000006" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000006_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494021676" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5527)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5527)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5517)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000006" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494023133" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5527)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5527)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5517)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000009" TASK_TYPE="MAP" START_TIME="1341494023138" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000007" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000007_0" START_TIME="1341494017328" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000007" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000007_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494024429" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 8 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6593)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6593)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6577)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(8)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(8)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000007" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494026143" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6593)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6593)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6577)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(8)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(8)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000010" TASK_TYPE="MAP" START_TIME="1341494029171" SPLITS="" .
Task TASKID="task_201207052014_0005_m_000011" TASK_TYPE="MAP" START_TIME="1341494032181" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000008" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000008_0" START_TIME="1341494021678" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000008" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000008_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494032221" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5355)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5355)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5347)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000008" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494035192" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5355)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5355)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5347)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000009" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000009_0" START_TIME="1341494024458" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000009" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000009_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494034859" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 7 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6927)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6927)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6913)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(7)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(7)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000009" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494035197" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6927)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(118)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21863)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6927)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6913)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(7)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(7)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(118)]}" .
Task TASKID="task_201207052014_0005_m_000012" TASK_TYPE="MAP" START_TIME="1341494038202" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000010" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000010_0" START_TIME="1341494032249" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000010" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000010_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494040236" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5724)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5724)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5712)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_m_000010" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494041209" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5724)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5724)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5712)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_m_000013" TASK_TYPE="MAP" START_TIME="1341494041210" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000011" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000011_0" START_TIME="1341494034887" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000011" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000011_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494042633" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6523)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6523)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6511)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_m_000011" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494044215" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6523)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6523)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6511)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_m_000014" TASK_TYPE="MAP" START_TIME="1341494047224" SPLITS="" .
Task TASKID="task_201207052014_0005_m_000015" TASK_TYPE="MAP" START_TIME="1341494050231" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000012" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000012_0" START_TIME="1341494040239" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000012" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000012_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494050744" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5510)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5510)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5498)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_m_000012" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494053235" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5510)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5510)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5498)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000013" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000013_0" START_TIME="1341494042670" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000013" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000013_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494051145" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5183)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5183)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5175)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_m_000013" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494053236" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5183)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5183)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5175)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_m_000016" TASK_TYPE="MAP" START_TIME="1341494059258" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000014" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000014_0" START_TIME="1341494050752" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000014" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000014_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494060547" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 4 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5213)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5213)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5205)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_m_000014" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494062264" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5213)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5213)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5205)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(4)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(4)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000015" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000015_0" START_TIME="1341494051168" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000015" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000015_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494060713" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 6 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6810)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6810)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6798)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_m_000015" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494062265" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6810)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6810)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6798)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(6)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(6)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_m_000017" TASK_TYPE="MAP" START_TIME="1341494062266" SPLITS="" .
Task TASKID="task_201207052014_0005_m_000018" TASK_TYPE="MAP" START_TIME="1341494068292" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000017" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000017_0" START_TIME="1341494062273" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000017" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000017_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494070299" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6261)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6261)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6251)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_m_000017" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494071298" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6261)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6261)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6251)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_m_000019" TASK_TYPE="MAP" START_TIME="1341494071299" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000016" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000016_0" START_TIME="1341494060550" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000016" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000016_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494071359" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6761)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6761)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6751)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_m_000016" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494074304" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(6761)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(6761)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(6751)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000018" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000018_0" START_TIME="1341494070327" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000018" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000018_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494083265" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 3 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5631)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5631)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5625)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(3)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(3)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_m_000018" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494083334" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5631)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5631)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5625)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(3)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(3)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000019" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000019_0" START_TIME="1341494071384" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207052014_0005_m_000019" TASK_ATTEMPT_ID="attempt_201207052014_0005_m_000019_0" TASK_STATUS="SUCCESS" FINISH_TIME="1341494083781" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="done with 5 records\." COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5420)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5420)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5410)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_m_000019" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494086411" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(5420)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(119)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(5420)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(5410)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(5)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(5)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(119)]}" .
Task TASKID="task_201207052014_0005_r_000000" TASK_TYPE="CLEANUP" START_TIME="1341494086414" SPLITS="" .
ReduceAttempt TASK_TYPE="CLEANUP" TASKID="task_201207052014_0005_r_000000" TASK_ATTEMPT_ID="attempt_201207052014_0005_r_000000_0" START_TIME="1341494086458" TRACKER_NAME="tracker_192\.168\.1\.104:localhost/127\.0\.0\.1:53808" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="CLEANUP" TASKID="task_201207052014_0005_r_000000" TASK_ATTEMPT_ID="attempt_201207052014_0005_r_000000_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1341494100874" SORT_FINISHED="1341494100874" FINISH_TIME="1341494100875" HOSTNAME="/default-rack/192\.168\.1\.104" STATE_STRING="cleanup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(0)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207052014_0005_r_000000" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1341494101452" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21864)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(0)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Job JOBID="job_201207052014_0005" FINISH_TIME="1341494101453" JOB_STATUS="SUCCESS" FINISHED_MAPS="20" FINISHED_REDUCES="0" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(119156)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(2370)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(437270)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(119156)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(118944)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(106)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(20)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1700003840)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(2370)][(MAP_OUTPUT_RECORDS)(Map output records)(106)]}" REDUCE_COUNTERS="" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(0)]}{(org\.apache\.hadoop\.mapred\.JobInProgress$Counter)(Job Counters )[(SLOTS_MILLIS_MAPS)(SLOTS_MILLIS_MAPS)(190892)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(20)][(SLOTS_MILLIS_REDUCES)(SLOTS_MILLIS_REDUCES)(21823)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(119156)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(2370)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(437270)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(119156)]}{(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)(org\.apache\.hadoop\.examples\.RandomTextWriter$Counters)[(BYTES_WRITTEN)(BYTES_WRITTEN)(118944)][(RECORDS_WRITTEN)(RECORDS_WRITTEN)(106)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(20)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1700003840)][(MAP_INPUT_BYTES)(Map input bytes)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(2370)][(MAP_OUTPUT_RECORDS)(Map output records)(106)]}" .
