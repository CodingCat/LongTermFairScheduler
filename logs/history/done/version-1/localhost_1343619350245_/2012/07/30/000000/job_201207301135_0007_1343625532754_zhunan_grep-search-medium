Meta VERSION="1" .
Job JOBID="job_201207301135_0007" JOBNAME="grep-search-medium" USER="zhunan" SUBMIT_TIME="1343625532754" JOBCONF="hdfs://localhost:9000/Users/zhunan/codes/hadoop/mapred/staging/zhunan/\.staging/job_201207301135_0007/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201207301135_0007" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201207301135_0007" LAUNCH_TIME="1343625533570" TOTAL_MAPS="6" TOTAL_REDUCES="5" JOB_STATUS="PREP" .
Task TASKID="task_201207301135_0007_m_000007" TASK_TYPE="SETUP" START_TIME="1343625542602" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201207301135_0007_m_000007" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000007_0" START_TIME="1343625544101" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53005" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201207301135_0007_m_000007" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000007_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343625552475" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="setup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21627)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Task TASKID="task_201207301135_0007_m_000007" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1343625554623" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21627)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Job JOBID="job_201207301135_0007" JOB_STATUS="RUNNING" .
Task TASKID="task_201207301135_0007_m_000000" TASK_TYPE="MAP" START_TIME="1343625554625" SPLITS="/default-rack/192\.168\.1\.100" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207301135_0007_m_000000" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000000_0" START_TIME="1343625554636" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53005" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207301135_0007_m_000000" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343625561043" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="hdfs://localhost:9000/user/zhunan/workloadgen/data/grep_data/part-00000:0+6105" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(6105)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(6229)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21785)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(6)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(188096512)][(MAP_INPUT_BYTES)(Map input bytes)(6105)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(124)]}" .
Task TASKID="task_201207301135_0007_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343625563659" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(6105)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(6229)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21785)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(6)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(188096512)][(MAP_INPUT_BYTES)(Map input bytes)(6105)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(124)]}" .
Task TASKID="task_201207301135_0007_m_000001" TASK_TYPE="MAP" START_TIME="1343625563661" SPLITS="/default-rack/192\.168\.1\.100" .
Task TASKID="task_201207301135_0007_m_000002" TASK_TYPE="MAP" START_TIME="1343625566685" SPLITS="/default-rack/192\.168\.1\.100" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207301135_0007_m_000001" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000001_0" START_TIME="1343625563667" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53005" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207301135_0007_m_000001" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343625569777" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="hdfs://localhost:9000/user/zhunan/workloadgen/data/grep_data/part-00001:0+5616" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(5616)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(5740)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21785)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(5)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(188096512)][(MAP_INPUT_BYTES)(Map input bytes)(5616)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(124)]}" .
Task TASKID="task_201207301135_0007_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343625572771" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(5616)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(5740)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21785)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(5)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(188096512)][(MAP_INPUT_BYTES)(Map input bytes)(5616)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(124)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207301135_0007_m_000002" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000002_0" START_TIME="1343625566797" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53005" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207301135_0007_m_000002" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343625572258" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="hdfs://localhost:9000/user/zhunan/workloadgen/data/grep_data/part-00010:0+5543" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(5543)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(5667)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21785)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(4)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(188096512)][(MAP_INPUT_BYTES)(Map input bytes)(5543)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(124)]}" .
Task TASKID="task_201207301135_0007_m_000002" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343625572773" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(5543)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(5667)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21785)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(4)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(188096512)][(MAP_INPUT_BYTES)(Map input bytes)(5543)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(124)]}" .
Task TASKID="task_201207301135_0007_m_000003" TASK_TYPE="MAP" START_TIME="1343625572774" SPLITS="/default-rack/192\.168\.1\.100" .
Task TASKID="task_201207301135_0007_m_000004" TASK_TYPE="MAP" START_TIME="1343625572775" SPLITS="/default-rack/192\.168\.1\.100" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207301135_0007_m_000003" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000003_0" START_TIME="1343625572844" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53005" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207301135_0007_m_000003" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343625582764" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="hdfs://localhost:9000/user/zhunan/workloadgen/data/grep_data/part-00002:0+5311" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(5311)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(5435)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21785)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(5)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(188096512)][(MAP_INPUT_BYTES)(Map input bytes)(5311)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(124)]}" .
Task TASKID="task_201207301135_0007_m_000003" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343625584893" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(5311)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(5435)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21785)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(5)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(188096512)][(MAP_INPUT_BYTES)(Map input bytes)(5311)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(124)]}" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207301135_0007_m_000004" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000004_0" START_TIME="1343625572891" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53005" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207301135_0007_m_000004" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000004_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343625582741" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="hdfs://localhost:9000/user/zhunan/workloadgen/data/grep_data/part-00011:0+5206" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(5206)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(5330)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21785)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(7)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(184619008)][(MAP_INPUT_BYTES)(Map input bytes)(5206)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(124)]}" .
Task TASKID="task_201207301135_0007_m_000004" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343625584894" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(5206)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(5330)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21785)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(7)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(184619008)][(MAP_INPUT_BYTES)(Map input bytes)(5206)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(124)]}" .
Task TASKID="task_201207301135_0007_m_000005" TASK_TYPE="MAP" START_TIME="1343625584895" SPLITS="/default-rack/192\.168\.1\.100" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207301135_0007_m_000005" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000005_0" START_TIME="1343625584898" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53005" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201207301135_0007_m_000005" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000005_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343625592361" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="hdfs://localhost:9000/user/zhunan/workloadgen/data/grep_data/part-00012:0+5155" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(5155)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(5279)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21785)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(6)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(188071936)][(MAP_INPUT_BYTES)(Map input bytes)(5155)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(124)]}" .
Task TASKID="task_201207301135_0007_m_000005" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1343625593942" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(5155)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(5279)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21785)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(30)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(6)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(188071936)][(MAP_INPUT_BYTES)(Map input bytes)(5155)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(124)]}" .
Task TASKID="task_201207301135_0007_r_000000" TASK_TYPE="REDUCE" START_TIME="1343625593943" SPLITS="" .
Task TASKID="task_201207301135_0007_r_000001" TASK_TYPE="REDUCE" START_TIME="1343625599972" SPLITS="" .
Task TASKID="task_201207301135_0007_r_000002" TASK_TYPE="REDUCE" START_TIME="1343625606000" SPLITS="" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207301135_0007_r_000000" TASK_ATTEMPT_ID="attempt_201207301135_0007_r_000000_0" START_TIME="1343625593951" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53005" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207301135_0007_r_000000" TASK_ATTEMPT_ID="attempt_201207301135_0007_r_000000_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1343625604394" SORT_FINISHED="1343625604439" FINISH_TIME="1343625609402" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="reduce > reduce" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21634)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(36)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207301135_0007_r_000000" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1343625612019" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21634)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(36)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207301135_0007_r_000003" TASK_TYPE="REDUCE" START_TIME="1343625612152" SPLITS="" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207301135_0007_r_000001" TASK_ATTEMPT_ID="attempt_201207301135_0007_r_000001_0" START_TIME="1343625600658" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53005" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207301135_0007_r_000001" TASK_ATTEMPT_ID="attempt_201207301135_0007_r_000001_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1343625611384" SORT_FINISHED="1343625611456" FINISH_TIME="1343625613212" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="reduce > reduce" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21634)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(36)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207301135_0007_r_000001" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1343625615167" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21634)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(36)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207301135_0007_r_000004" TASK_TYPE="REDUCE" START_TIME="1343625624219" SPLITS="" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207301135_0007_r_000002" TASK_ATTEMPT_ID="attempt_201207301135_0007_r_000002_0" START_TIME="1343625609426" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53005" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207301135_0007_r_000002" TASK_ATTEMPT_ID="attempt_201207301135_0007_r_000002_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1343625620612" SORT_FINISHED="1343625620983" FINISH_TIME="1343625626484" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="reduce > reduce" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21634)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(36)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207301135_0007_r_000002" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1343625627225" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21634)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(36)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207301135_0007_r_000003" TASK_ATTEMPT_ID="attempt_201207301135_0007_r_000003_0" START_TIME="1343625613231" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53005" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207301135_0007_r_000003" TASK_ATTEMPT_ID="attempt_201207301135_0007_r_000003_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1343625623278" SORT_FINISHED="1343625623309" FINISH_TIME="1343625625160" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="reduce > reduce" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21634)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(36)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207301135_0007_r_000003" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1343625627237" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21634)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(36)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207301135_0007_r_000004" TASK_ATTEMPT_ID="attempt_201207301135_0007_r_000004_0" START_TIME="1343625625162" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53005" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201207301135_0007_r_000004" TASK_ATTEMPT_ID="attempt_201207301135_0007_r_000004_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1343625633657" SORT_FINISHED="1343625633701" FINISH_TIME="1343625639602" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="reduce > reduce" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21634)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(36)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207301135_0007_r_000004" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1343625642261" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(86)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(6)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21634)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(86)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(36)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" .
Task TASKID="task_201207301135_0007_m_000006" TASK_TYPE="CLEANUP" START_TIME="1343625642264" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201207301135_0007_m_000006" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000006_0" START_TIME="1343625642270" TRACKER_NAME="tracker_192\.168\.1\.100:localhost/127\.0\.0\.1:53005" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201207301135_0007_m_000006" TASK_ATTEMPT_ID="attempt_201207301135_0007_m_000006_0" TASK_STATUS="SUCCESS" FINISH_TIME="1343625647554" HOSTNAME="/default-rack/192\.168\.1\.100" STATE_STRING="cleanup" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21627)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Task TASKID="task_201207301135_0007_m_000006" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1343625648272" COUNTERS="{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(21627)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(85000192)]}" .
Job JOBID="job_201207301135_0007" FINISH_TIME="1343625648288" JOB_STATUS="SUCCESS" FINISHED_MAPS="6" FINISHED_REDUCES="5" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(32936)]}{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(33680)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(130710)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(180)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(MAP_INPUT_RECORDS)(Map input records)(33)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1125076992)][(MAP_INPUT_BYTES)(Map input bytes)(32936)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(744)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)]}" REDUCE_COUNTERS="{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(430)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(30)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(108170)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(430)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(180)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(425000960)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)]}" COUNTERS="{(org\.apache\.hadoop\.mapred\.FileInputFormat$Counter)(File Input Format Counters )[(BYTES_READ)(Bytes Read)(32936)]}{(org\.apache\.hadoop\.mapred\.JobInProgress$Counter)(Job Counters )[(SLOTS_MILLIS_MAPS)(SLOTS_MILLIS_MAPS)(58869)][(TOTAL_LAUNCHED_REDUCES)(Launched reduce tasks)(5)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(6)][(DATA_LOCAL_MAPS)(Data-local map tasks)(6)][(SLOTS_MILLIS_REDUCES)(SLOTS_MILLIS_REDUCES)(71432)]}{(org\.apache\.hadoop\.mapred\.FileOutputFormat$Counter)(File Output Format Counters )[(BYTES_WRITTEN)(Bytes Written)(430)]}{(FileSystemCounters)(FileSystemCounters)[(FILE_BYTES_READ)(FILE_BYTES_READ)(30)][(HDFS_BYTES_READ)(HDFS_BYTES_READ)(33680)][(FILE_BYTES_WRITTEN)(FILE_BYTES_WRITTEN)(238880)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(430)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_OUTPUT_MATERIALIZED_BYTES)(Map output materialized bytes)(180)][(MAP_INPUT_RECORDS)(Map input records)(33)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(180)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1550077952)][(MAP_INPUT_BYTES)(Map input bytes)(32936)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(SPLIT_RAW_BYTES)(SPLIT_RAW_BYTES)(744)][(REDUCE_INPUT_RECORDS)(Reduce input records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(0)][(MAP_OUTPUT_RECORDS)(Map output records)(0)]}" .
